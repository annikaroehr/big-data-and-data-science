{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/saschaschworm/big-data-and-data-science/blob/master/notebooks/development-exercises/backorder-random-forest.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://github.com/saschaschworm/big-data-and-data-science/blob/master/datasets/exercises/backorders.csv?raw=true')\n",
    "X, y = data.iloc[:, 0:10], data['went_on_backorder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_featues = list(data.iloc[:, -2:-1].columns)\n",
    "numerical_features = list(data.iloc[:, 0:9].columns)\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('onehotencoder', OneHotEncoder(drop='first')),\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('categorical_transformer', categorical_transformer, categorical_featues),\n",
    "    ('numerical_transformer', numerical_transformer, numerical_features),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('model', RandomForestClassifier(random_state=1909)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_scorer = make_scorer(f1_score, pos_label='yes')\n",
    "n_estimators, max_depth = randint(200, 400), randint(50, 100)\n",
    "param_distributions = {'model__n_estimators': n_estimators, 'model__max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Optimal parameters: {'model__max_depth': 63, 'model__n_estimators': 343}\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RandomizedSearchCV(pipeline, param_distributions=param_distributions, \n",
    "                        n_iter=5, scoring=custom_scorer, n_jobs=-1, iid=False, \n",
    "                        cv=10, random_state=1909)\n",
    "rs = rs.fit(X, y)\n",
    "f'Optimal parameters: {rs.best_params_}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=rs.best_params_['model__n_estimators'], \n",
    "                               max_depth=rs.best_params_['model__max_depth'], \n",
    "                               random_state=1909)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('model', model),\n",
    "])\n",
    "\n",
    "pipeline = pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 on Training and Test Sets: 97.38/89.74\n"
     ]
    }
   ],
   "source": [
    "res_cv = cross_validate(pipeline, X, y, scoring=custom_scorer, cv=10, return_train_score=True)\n",
    "res_f1_tr = np.mean(res_cv['train_score']) * 100\n",
    "res_f1_te = np.mean(res_cv['test_score']) * 100\n",
    "print(f'Average F1 on Training and Test Sets: {res_f1_tr:.2f}/{res_f1_te:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_set = pd.DataFrame([[100, 0, 2, 5, 6, 1, 2, 5, 1, 'no']], columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(prediction_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80758017, 0.19241983]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict_proba(prediction_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
