{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/saschaschworm/big-data-and-data-science/blob/master/notebooks/demos/outage-decision-tree-learning.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/demos/outages.csv')\n",
    "X, y = data.iloc[:, 0:3], data['outage']\n",
    "\n",
    "hyperparams = {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, \n",
    "               'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': None, \n",
    "               'random_state': 1909, 'max_leaf_nodes': None, 'min_impurity_decrease':0.0, \n",
    "               'min_impurity_split': None}\n",
    "\n",
    "model = DecisionTreeClassifier(**hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_featues = ['vibration', 'error', 'temperature']\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('onehotencoder', OneHotEncoder(drop='first')),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('categorical_transformer', categorical_transformer, categorical_featues),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('model', model),\n",
    "])\n",
    "\n",
    "pipeline = pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Prediction result: ['no'] ([[1. 0.]])\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance = pd.DataFrame({'vibration': ['medium'], 'error': ['yes'], 'temperature': ['low']})\n",
    "\n",
    "prediction = pipeline.predict(instance)\n",
    "prediction_proba = pipeline.predict_proba(instance)\n",
    "f'Prediction result: {prediction} ({prediction_proba})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Average F1 on Training and Test Sets: 100.00%/91.67%'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_scorer = make_scorer(f1_score, pos_label='yes')\n",
    "res_cv = cross_validate(pipeline, X, y, scoring=custom_scorer, cv=4, return_train_score=True)\n",
    "\n",
    "res_f1_tr = np.mean(res_cv['train_score']) * 100\n",
    "res_f1_te = np.mean(res_cv['test_score']) * 100\n",
    "f'Average F1 on Training and Test Sets: {res_f1_tr:.2f}%/{res_f1_te:.2f}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'n_estimators': 4, 'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, \n",
    "    'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', \n",
    "    'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, \n",
    "    'bootstrap': True, 'oob_score': False, 'n_jobs': None, 'random_state': 1909, \n",
    "    'verbose': 0, 'warm_start': False, 'class_weight': None}\n",
    "\n",
    "model = RandomForestClassifier(**hyperparams)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('model', model),\n",
    "])\n",
    "\n",
    "pipeline = pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Average F1 on Training and Test Sets: 97.73%/75.00%'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cv = cross_validate(pipeline, X, y, scoring=custom_scorer, cv=4, return_train_score=True)\n",
    "res_f1_tr = np.mean(res_cv['train_score']) * 100\n",
    "res_f1_te = np.mean(res_cv['test_score']) * 100\n",
    "f'Average F1 on Training and Test Sets: {res_f1_tr:.2f}%/{res_f1_te:.2f}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = randint(100, 500)\n",
    "max_depth = randint(1, 10)\n",
    "param_distributions = {'model__n_estimators': n_estimators, 'model__max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomizedSearchCV(pipeline, param_distributions=param_distributions, n_iter=5, \n",
    "                        scoring=custom_scorer, n_jobs=-1, iid=False, cv=4, random_state=1909)\n",
    "rs = rs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Optimal parameters: {'model__max_depth': 6, 'model__n_estimators': 442}\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Optimal parameters: {rs.best_params_}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 200, 300, 400, 500]\n",
    "max_depth = [1, 2, 3, 5, 6, 7, 8, 9, 10]\n",
    "param_grid = {'model__n_estimators': n_estimators,  'model__max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipeline, param_grid=param_grid, scoring=custom_scorer, n_jobs=-1, \n",
    "                  iid=False, cv=4)\n",
    "gs = gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Optimal parameters: {'model__max_depth': 3, 'model__n_estimators': 400}\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Optimal parameters: {gs.best_params_}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
